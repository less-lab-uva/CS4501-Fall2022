---
title: Lab E
subtitle: Robotics and Ethics
layout: page
---

# Robotics and Ethics

[Ethics](https://plato.stanford.edu/entries/ethics-ai/) -- the moral principles that govern a person's conduct or engagement in an activity -- 
and its role in tech is becoming a more widely and contentiously debated topic.
[Robotics often sits at the heart of that debate](https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/study-shows-that-humans-attribute-morals-and-emotions-to-robots) because it’s a highly experimental field, 
full of emerging technology from “internet of things“ to “AI”, 
and lends itself to open-ended development with tons of room for growth accompanied by unclear social-economical implications for the future.

For example, consider the following question: should we keep full autonomy out of the reach of robots? 
On one hand, if the autonomous capabilities in question involve high levels of risk, such as using deadly force or making impactful decisions about quality of life, full autonomy may be deemed too difficult of a task to automate correctly.
On the other hand, it could be deemed worth the risk if it protects others from physical harm. Answering such a question requires a deep understanding of the context in which the question is posed, the factors to be considered, and a systematic study of the implications of each potential answer under multiple and often uncertain scenarios. 

Given the relevance of ethics to robotics and closely related fields, in this lab we will explore a series of technical scenarios with inherent ethical problems, take a position, and develop arguments to support those positions.


# Learning Objectives

At the end of this lab, you should understand:
* How to synthesize meaningful questions from situations that present ethical problems.
* How to find and use related work that informs these questions.
* How to connect the current state of the art to possible future scenarios and their implications. 
* How to participate in debating ethical questions in a respectful and productive way.

{% include notification.html message="Submission: The checkpoints are handled a little differently for this lab. The first checkpoint will consist of a  written document that must be submitted via Collab before class on October 12th. The second checkpoint is the actual in-class debate on October 12th." 
status="is-success" 
icon="fas fa-exclamation-triangle" %}

# Activity
The lab consists of two parts: **Preparation** and **Debate**.

## Part 1: Preparation

Start by forming a team with other class members (teams of 3) and pick one of the **prompts** provided in the next section. Then, your team must pick a side -- affirmative or negative -- and begin to build an argument around that position (more details on building the argument are found later in this document). 

After you form a team, your team must sign up for a prompt and affirmative/negative positions in
[this google spreadsheet](https://docs.google.com/spreadsheets/d/14P6ccK_N2kmGguAlfEjwIMGkgzYyUN1Uk8nzB8UJiyc/edit?usp=sharing).
The link is visible to anyone who is logged into their UVA Google Drive account, 
Signup is on a first come, first serve basis so sign up quickly if you see a prompt you really like.
Note that teams on opposite positions of the same prompt will be debating against each other.

For example, let's say my team chooses a prompt like "Should businesses be allowed to make companionship robots for widespread commercial production?", and the position that I've chosen is affirmative; i.e. I've answered the question with a "Yes, they should be allowed to."
We would then look for sources to support the positive effects of having a companionship robot on the individual who buys one. For example, I might look at [social robots for the elderly](https://www.vox.com/future-perfect/2020/9/9/21418390/robots-pandemic-loneliness-isolation-elderly-seniors) and [interactive sex robots](https://www.forbes.com/sites/bernardmarr/2020/11/30/future-of-intimacy-sex-bots-virtual-reality-and-smart-sex-toys/?sh=39b5af7738fa) for those who struggle with intimacy, as well as what [healthcare professionals see as the benefits and drawbacks](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6719485/) of using them.
Then, I would point to possible future contexts in which the benefits and drawbacks of today might be amplified or fundamentally shifted, like the isolated, space-dwelling humans' relationships with their androids in Philip K. Dick's *[Do Androids Dream of Electric Sheep?](https://www.nature.com/articles/d41586-018-02695-7)*. 

### Prompts

The prompts to choose from are:
1. Should [moral machines](https://www.media.mit.edu/publications/moral-machine-perception-of-moral-judgment-made-by-machines/) drive the analysis of risk when human life is involved? 
2. Should [sentient robots](https://www.nbcnews.com/mach/tech/what-rise-sentient-robots-will-mean-human-beings-ncna773146) have the same rights as humans?
3. Should a [caretaking/personal assistant robot](https://ieeexplore.ieee.org/abstract/document/5980058?casa_token=V_F525cBorwAAAAA:3_PgIxa4xJ2ne9vSWF_hKAGK6s7JrADljtNiuG42-5ZjcNPGjiZYGvAmDMk3YlOxgMha85uv) have control over the daily activities of their human (food, medicine, exercise, bedtime/waking time, etc.)? 
4. Should [law enforcement agencies use robots](https://builtin.com/robotics/police-robot-law-enforcement) to uphold the law?
5. Should the [right to repair](https://www.nytimes.com/2020/10/23/climate/right-to-repair.html) be available to everyone who owns a robot?


### Gathering Sources to Build your Argument
 
We have provided a single source for you to help pick your topic and get started with your research, but you will need to incorporate more sources to understand your topic and formulate your argument. You can use as many additional sources as you need to support your position. To show that you have a well-informed position on the topic, you will need to do some background research and critical thinking about the sources you find. 

In the outline required for *Checkpoint 1* you must cite and include a variety of  sources that contribute to your argument. Here are the source types required with examples for the illustration prompt we mentioned earlier "Should businesses be allowed to make companionship robots for widespread commercial production?”:

1. At least two news articles that characterize the ways in which the target problem is present today.  Examples of this   might be the Vox article on [social robots for the elderly](https://www.vox.com/future-perfect/2020/9/9/21418390/robots-pandemic-loneliness-isolation-elderly-seniors) and the Forbes article on [interactive sex robots](https://www.forbes.com/sites/bernardmarr/2020/11/30/future-of-intimacy-sex-bots-virtual-reality-and-smart-sex-toys/?sh=39b5af7738fa) mentioned earlier.

2. At least one peer-reviewed writing such as a research article, journal, or book on ethics/fairness/discrimination in a field related to your prompt to back up your debate position. An example of this might be the [NIH study on what healthcare professionals see as the benefits and drawbacks of companion robots](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6719485/) mentioned earlier.

3. One motivating example that is either from an anecdotal account, or that has enough documented support to be a believably common occurrence. An example of this could be this human interest story from MIT on [sending robots to libraries to read to underprivileged children](https://www.media.mit.edu/projects/collaborative-robot-storyteller/overview/).

4. One **well-known** sci-fi/futuristic work of fiction that incorporates robots to use as a framing device for the future consequences or implications of the position you or your opponent may take on the prompt. Favor ones with which your audience may be familiar. For example, we might assume that most people have seen *2001: A Space Odyssey* and are passingly familiar with the concept of a robot controlling a space ship, but most people are not familiar with the Kubrickian interpretation of the ending in which the main character is supposedly held captive in an alien zoo. 
In the context of companion robots, a good choice of sci-fi could be Philip K. Dick's *[Do Androids Dream of Electric Sheep?](https://www.nature.com/articles/d41586-018-02695-7)* or "Dolores", the robot host from the 2016 reprise of TV series *[Westworld](https://www.imdb.com/title/tt0475784/)*. 
    
Think about your audience (i.e. your classmates and the teaching staff) and plan carefully as you choose your source material, building them to address the questions of Checkpoint 1 (see below).  

You must cite (but not plagiarize) the research and arguments of others when building your related work.  


### Outlining Your Argument

When organizing your argument, you will have stronger and weaker points. Make sure your argument has a logical flow. 
Arguments are often organized according to points that the audience can easily agree with.
Getting audience "buy-in" early on can help when leading them along to your more complicated or difficult-to-accept arguments.

For example, there are lots of ways to structure an argument for an affirmative position to my example question "Should people be using companion robots en masse?". 
What's important is that I have solid reasons for why certain arguments are more compelling.
Let's say I have three arguments prepared:

<ol>
<li>Companion robots improve the quality of life for lots of people, the ones that they affect directly and many others that they affect indirectly. 
    <ol type="I">
    <li>Companion robots free up counselors and therapists to work on more complex problems.</li>
    <li>Companion robots help those with social and sexual disorders gain confidence, resulting in stronger human-to-human relationships. </li>
    </ol>
</li>
<li>Companion robots are excellent way to introduce robots into society and improve public opinion about robots.</li>
<li>Companion robots strengthen the economy and create jobs.</li>
</ol>

I've organized them this way because I believe I can confidently argue that the well-being of humans is the highest priority and the main purpose of companion robots, as well as an easy priority for much of my audience. That main point is followed by weaker points that I believe less people will think are important -- social opinion of robots and the health of the economy. 

Additionally, keep in mind the potential counterarguments. Acknowledging your opponent's points shows that you have a well thought out, 
comprehensive position and disarms your opponent ahead of time.
The negative position towards my example question might argue that companion robots might, through poor programming, hurt the people they are meant to be helping. 
Anticipating that, I might include a point in my argument that a companion robot only has the capabilities we equip it with, and its size and shape could be constrained to be light enough to be lifted by a human or to be made of only soft, bouncy materials that cannot damage people or structures.


## Checkpoint 1

With your team, write up a 2-page outline of your position and how you intend to argue it, with all relevant sources cited. Each team will submit exactly one outline, but be sure to include the names of all team members in the submission.

Your outline should include bulletpoints with a level of detail similar to the ones shown above, so you can easily reference this outline during your debate.
In this outline, organize your arguments to address the following questions:
1. How is this problem relevant today? 
2. Why should the average person care? The average computer scientist?
3. What are the potential consequences/future outcome if your position is not followed? What is the science fiction portrayal of this future?
4. Does this position set a problematic precedent?
5. Can your position be legislated? Can that legislation be enforced? Can it be incentivized?
6. Under what circumstances might the counterarguments to your position be acceptable? Are those circumstances realistic? 

**This checkpoint must be submitted through Collab before the in-lab debate (October 12, 2022).** Part of the grade for this lab is based on how well you've prepared, and this outline is how we will determine that.  


## Part 2: Debate
On the day of the lab, teams on opposite sides of the same prompt will debate each other and a winner will be chosen by the moderators.
*Winning your debate won't affect your ability to earn a 100% on this lab (the lab is worth 5 points), but it will earn you one extra credit point towards your lab grade.*

Due to the class size and our limited amount of time, we will be dividing the class into two large groups and conducting debates in parallel.

Each debate will be 11 minutes long, broken down into an introduction to the topic, timed rebuttals, and a period of question-and-answer from the moderators and audience. At the end of the debate, the moderators will select a winner, and the winning team will earn an extra credit point towards their lab grade.
After splitting the class into two large groups, there will be 10 teams per group. For both large groups, the same 5 debates will be held (with two teams per debate -- one affirmative (Team A), one negative (Team B)).

Prior to the debate, each team must assign its members to cover each of the following roles:
* Introduction and opening points (hereby referred to as "Student1X" for team X)
* Rebuttal and new points (hereby referred to as "Student2X" for team X)
* Q&A Representative (hereby referred to as "Student3X" for team X)

The structure of each debate is as follows:
1. Introduction to the topic & opening points by Student1A (affirmative position): 2 minutes
2. Rebuttal & new points by Student1B (negative position): 2 minutes
3. Rebuttal & new points by Student2A (affirmative position): 2 minutes
4. Rebuttal, new points, and closing remarks by Student2B (negative position): 2 minutes
5. Questions from moderators and audience, answered by Student3A and Student3B: 2-3 minutes
6. Transition to the next debate

During the debate, keep these rules in mind:
* Moderators will cut you off at 2 minutes. Moderators will signal when 30 seconds remain. Be mindful of this so you aren't cut off mid-sentence. 
* There is no time in between introduction and rebuttals, being prepared and thinking on your feet will be key to winning the argument
* Questions can be asked to either team, or both teams.


### Preparing for the Debate

When preparing for the debate, keep in mind the debate structure, delivery of your message, and that your responses stay on topic and within time. Do not read from notecards or prewritten pages, since it is important to make eye contact with your audience. Keep in mind the length of your responses so the moderator does not cut you off mid-sentence.
You may want to do a dry run of your debate arguments  with your teammates or practice explaining the context of the question and your arguments to friends to see how a person unfamiliar with the topic would understand your presentation.


##  Checkpoint 2
 
1. The speakers’ statements clearly supported their position. (25%)
2. Arguments were presented with clarity and appropriate volume.  (25%)
3. Rebuttals were specific to opposing arguments and expressed with clarity.  (25%)
4. Answers during Q&A were precise and thoughtful.  (25%)
5. Winner as per moderator decision (+1 extra credit point)

 
# Extra
 
Here are just a few papers from researchers who are currently working in topics of fairness, ethics, and discrimination in robotics and beyond, that may be good for background reading:
+ [Ron Arkin](https://www.cc.gatech.edu/aimosaic/faculty/arkin/)
+ [Jean-François Bonnefon](https://science.sciencemag.org/content/352/6293/1573)
+ [Eric Martinez](https://www.frontiersin.org/articles/10.3389/frobt.2021.788355/full)
+ [Luis Seabra Lopes](https://www.researchgate.net/publication/3453963_Sentience_in_Robots_Applications_and_Challenges)
+ [Joanna J. Bryson](http://www.cs.bath.ac.uk/~jjb/ftp/Bryson19AIforLawofAI.pdf)
+ [Katya Klinova](https://arxiv.org/abs/2011.02787)
+ [Patrick Lin](https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1004&context=phil_fac)
+ [Margaret Mitchell](https://arxiv.org/pdf/1801.07593)
+ [Iyad Rahwan](https://www.nature.com/articles/s41586-018-0637-6)
+ [Stuart Rusel](http://people.eecs.berkeley.edu/~russell/) 
+ [Kush Varshney](http://www.cs.cmu.edu/~rnoothig/papers/policy_orchestration.pdf)
+ [Aimee van Wynsberghe](https://link.springer.com/article/10.1007/s11948-011-9343-6)
+ [IEEE Ethics in Action](https://ethicsinaction.ieee.org/)
+ [Online Ethics Center for Engineering and Science](https://onlineethics.org/)
